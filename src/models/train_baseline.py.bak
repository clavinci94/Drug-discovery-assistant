import os, json
import numpy as np
import pandas as pd
from typing import Tuple
from sklearn.metrics import roc_auc_score, accuracy_score, average_precision_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from joblib import dump
import torch

from src.models.baselines import build_random_forest, RFConfig, MLP

DATA_CSV = "data/processed/dataset_molecules.csv"
FP_NPZ = "data/processed/morgan_fp.npz"
ARTIF_DIR = "models"

def load_dataset() -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:
    if not (os.path.exists(DATA_CSV) and os.path.exists(FP_NPZ)):
        raise FileNotFoundError("Dataset fehlt. Bitte zuerst Phase-1-Preprocessing laufen lassen.")
    df = pd.read_csv(DATA_CSV)
    fps = np.load(FP_NPZ)["X"]
    y = df["label_active"].values.astype(int)
    desc_cols = ["MolWt","MolLogP","TPSA","NumHAcceptors","NumHDonors","NumRotatableBonds","RingCount"]
    if all(c in df.columns for c in desc_cols):
        X_desc = df[desc_cols].fillna(0).values.astype(np.float32)
        X = np.hstack([fps, X_desc])
    else:
        X = fps
    return X.astype(np.float32), y, df

def evaluate_and_log(y_true, y_prob, y_pred, split: str):
    metrics = {
        "split": split,
        "roc_auc": float(roc_auc_score(y_true, y_prob)),
        "pr_auc": float(average_precision_score(y_true, y_prob)),
        "accuracy": float(accuracy_score(y_true, y_pred)),
        "report": classification_report(y_true, y_pred, output_dict=True),
        "confusion_matrix": confusion_matrix(y_true, y_pred).tolist()
    }
    print(f"\n== {split} metrics ==")
    print(f"AUC: {metrics['roc_auc']:.3f} | PR-AUC: {metrics['pr_auc']:.3f} | ACC: {metrics['accuracy']:.3f}")
    return metrics

def train_rf():
    X, y, df = load_dataset()
    X, y = shuffle(X, y, random_state=42)
    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
    rf = build_random_forest(RFConfig())
    rf.fit(Xtr, ytr)
    prob_tr = rf.predict_proba(Xtr)[:,1]; pred_tr = (prob_tr >= 0.5).astype(int)
    mtr = evaluate_and_log(ytr, prob_tr, pred_tr, "train")
    prob_te = rf.predict_proba(Xte)[:,1]; pred_te = (prob_te >= 0.5).astype(int)
    mte = evaluate_and_log(yte, prob_te, pred_te, "test")
    os.makedirs(ARTIF_DIR, exist_ok=True)
    dump(rf, os.path.join(ARTIF_DIR, "baseline_rf.joblib"))
    with open(os.path.join(ARTIF_DIR, "baseline_rf_metrics.json"), "w") as f:
        json.dump({"train": mtr, "test": mte}, f, indent=2)
    print(f"✅ Gespeichert: {os.path.join(ARTIF_DIR,'baseline_rf.joblib')}")

def train_mlp(epochs: int = 8, lr: float = 1e-3, batch_size: int = 256):
    from src.models.baselines import MLP
    X, y, df = load_dataset()
    X, y = shuffle(X, y, random_state=42)
    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = MLP(in_dim=X.shape[1]).to(device)
    opt = torch.optim.Adam(model.parameters(), lr=lr)
    bce = torch.nn.BCEWithLogitsLoss()
    def batches(X, y, bs):
        n = len(X)
        for i in range(0, n, bs):
            yield X[i:i+bs], y[i:i+bs]
    for ep in range(1, epochs+1):
        model.train(); total = 0.0
        for xb, yb in batches(Xtr, ytr, batch_size):
            xb = torch.tensor(xb, dtype=torch.float32, device=device)
            yb = torch.tensor(yb, dtype=torch.float32, device=device)
            opt.zero_grad()
            loss = bce(model(xb).squeeze(-1), yb)
            loss.backward(); opt.step()
            total += loss.item() * len(xb)
        print(f"Epoch {ep}/{epochs} - loss: {total/len(Xtr):.4f}")
    model.eval()
    with torch.no_grad():
        te_logits = []
        for i in range(0, len(Xte), 1024):
            xb = torch.tensor(Xte[i:i+1024], dtype=torch.float32, device=device)
            te_logits.append(model(xb).squeeze(-1).cpu())
        te_logits = torch.cat(te_logits)
        te_prob = torch.sigmoid(te_logits).numpy()
    te_pred = (te_prob >= 0.5).astype(int)
    mte = evaluate_and_log(yte, te_prob, te_pred, "test")
    os.makedirs(ARTIF_DIR, exist_ok=True)
    torch.save(model.state_dict(), os.path.join(ARTIF_DIR, "baseline_mlp.pt"))
    with open(os.path.join(ARTIF_DIR, "baseline_mlp_metrics.json"), "w") as f:
        json.dump({"test": mte}, f, indent=2)
    print(f"✅ Gespeichert: {os.path.join(ARTIF_DIR,'baseline_mlp.pt')}")

if __name__ == "__main__":
    import argparse
    p = argparse.ArgumentParser()
    p.add_argument("--model", choices=["rf","mlp"], default="rf")
    p.add_argument("--epochs", type=int, default=8)
    p.add_argument("--lr", type=float, default=1e-3)
    p.add_argument("--batch_size", type=int, default=256)
    args = p.parse_args()
    if args.model == "rf":
        train_rf()
    else:
        train_mlp(epochs=args.epochs, lr=args.lr, batch_size=args.batch_size)
